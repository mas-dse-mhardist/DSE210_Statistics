{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "/Users/mikihardisty/Documents/DSE/mhardist/DSE210/homework2/20news-bydate\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame, read_csv\n",
    "from __future__ import division\n",
    "\n",
    "%cd ~/mhardist/DSE210/homework2/20news-bydate/\n",
    "\n",
    "#Get the training data\n",
    "X= pd.read_csv('../20news-bydate2/matlab/train.data', delim_whitespace=True, names=['doc_idx','word_idx','occurance_count'])\n",
    "Y = pd.read_csv('../20news-bydate2/matlab/train.label', delim_whitespace=True , names=['label_idx'])\n",
    "Y['doc_idx'] = Y.index + 1\n",
    "\n",
    "#Get the test data\n",
    "X_test = pd.read_csv('../20news-bydate2/matlab/test.data', delim_whitespace=True, names=['doc_idx','word_idx','occurance_count'])\n",
    "Y_test = pd.read_csv('../20news-bydate2/matlab/test.label', delim_whitespace=True , names=['label_idx'])\n",
    "Y_test['doc_idx'] = Y_test.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_idx</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archive</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atheism</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resources</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alt</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>last</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>modified</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>december</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>version</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atheist</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>addresses</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>organizations</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>usa</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>freedom</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>from</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>religion</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>foundation</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>darwin</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fish</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bumper</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stickers</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>and</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>assorted</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>other</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>paraphernalia</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>are</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>available</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>in</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61158</th>\n",
       "      <td>sectarians</td>\n",
       "      <td>61159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61159</th>\n",
       "      <td>talmage</td>\n",
       "      <td>61160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61160</th>\n",
       "      <td>preexistent</td>\n",
       "      <td>61161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61161</th>\n",
       "      <td>exod</td>\n",
       "      <td>61162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61162</th>\n",
       "      <td>tetragrammation</td>\n",
       "      <td>61163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61163</th>\n",
       "      <td>triune</td>\n",
       "      <td>61164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61164</th>\n",
       "      <td>adon</td>\n",
       "      <td>61165</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61165</th>\n",
       "      <td>atoning</td>\n",
       "      <td>61166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61166</th>\n",
       "      <td>tidings</td>\n",
       "      <td>61167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61167</th>\n",
       "      <td>maketh</td>\n",
       "      <td>61168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61168</th>\n",
       "      <td>spreadeth</td>\n",
       "      <td>61169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61169</th>\n",
       "      <td>bhagwans</td>\n",
       "      <td>61170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61170</th>\n",
       "      <td>anchovy</td>\n",
       "      <td>61171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61171</th>\n",
       "      <td>vanishingly</td>\n",
       "      <td>61172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61172</th>\n",
       "      <td>ktikkane</td>\n",
       "      <td>61173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61173</th>\n",
       "      <td>ramses</td>\n",
       "      <td>61174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61174</th>\n",
       "      <td>orontes</td>\n",
       "      <td>61175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61175</th>\n",
       "      <td>chariotry</td>\n",
       "      <td>61176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61176</th>\n",
       "      <td>amun</td>\n",
       "      <td>61177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61177</th>\n",
       "      <td>deist</td>\n",
       "      <td>61178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>devoutly</td>\n",
       "      <td>61179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61179</th>\n",
       "      <td>smugly</td>\n",
       "      <td>61180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61180</th>\n",
       "      <td>tartaros</td>\n",
       "      <td>61181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61181</th>\n",
       "      <td>bibical</td>\n",
       "      <td>61182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61182</th>\n",
       "      <td>tophet</td>\n",
       "      <td>61183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61183</th>\n",
       "      <td>aeroplane</td>\n",
       "      <td>61184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>gosple</td>\n",
       "      <td>61185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>ephas</td>\n",
       "      <td>61186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>kltensme</td>\n",
       "      <td>61187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>etrbom</td>\n",
       "      <td>61188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61188 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  word_idx  key\n",
       "0              archive         1    1\n",
       "1                 name         2    1\n",
       "2              atheism         3    1\n",
       "3            resources         4    1\n",
       "4                  alt         5    1\n",
       "5                 last         6    1\n",
       "6             modified         7    1\n",
       "7             december         8    1\n",
       "8              version         9    1\n",
       "9              atheist        10    1\n",
       "10           addresses        11    1\n",
       "11                  of        12    1\n",
       "12       organizations        13    1\n",
       "13                 usa        14    1\n",
       "14             freedom        15    1\n",
       "15                from        16    1\n",
       "16            religion        17    1\n",
       "17          foundation        18    1\n",
       "18              darwin        19    1\n",
       "19                fish        20    1\n",
       "20              bumper        21    1\n",
       "21            stickers        22    1\n",
       "22                 and        23    1\n",
       "23            assorted        24    1\n",
       "24               other        25    1\n",
       "25       paraphernalia        26    1\n",
       "26                 are        27    1\n",
       "27           available        28    1\n",
       "28                 the        29    1\n",
       "29                  in        30    1\n",
       "...                ...       ...  ...\n",
       "61158       sectarians     61159    1\n",
       "61159          talmage     61160    1\n",
       "61160      preexistent     61161    1\n",
       "61161             exod     61162    1\n",
       "61162  tetragrammation     61163    1\n",
       "61163           triune     61164    1\n",
       "61164             adon     61165    1\n",
       "61165          atoning     61166    1\n",
       "61166          tidings     61167    1\n",
       "61167           maketh     61168    1\n",
       "61168        spreadeth     61169    1\n",
       "61169         bhagwans     61170    1\n",
       "61170          anchovy     61171    1\n",
       "61171      vanishingly     61172    1\n",
       "61172         ktikkane     61173    1\n",
       "61173           ramses     61174    1\n",
       "61174          orontes     61175    1\n",
       "61175        chariotry     61176    1\n",
       "61176             amun     61177    1\n",
       "61177            deist     61178    1\n",
       "61178         devoutly     61179    1\n",
       "61179           smugly     61180    1\n",
       "61180         tartaros     61181    1\n",
       "61181          bibical     61182    1\n",
       "61182           tophet     61183    1\n",
       "61183        aeroplane     61184    1\n",
       "61184           gosple     61185    1\n",
       "61185            ephas     61186    1\n",
       "61186         kltensme     61187    1\n",
       "61187           etrbom     61188    1\n",
       "\n",
       "[61188 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the vocabulary words\n",
    "V = pd.read_csv('../vocabulary.txt', header=None)\n",
    "V.columns = ['word']\n",
    "V['word_idx'] = [a for a in range(1,len(V)+1)]\n",
    "V['key'] = 1\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = pd.Series([i+1 for i in range(20)], index=[i+1 for i in range(20)]).to_frame()\n",
    "s['key'] = 1\n",
    "s.columns = ['label_idx', 'key']\n",
    "s = pd.merge(V, s, on='key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a multinomial Naive Bayes model using the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &pi;<sub>j</sub> \n",
    "### Get the fraction of documents that belong to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_idx</th>\n",
       "      <th>Pi_j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.042595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.051557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.050759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.052090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.051025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.051646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.052888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.052711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.053066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.052711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.052445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.052711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.052622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.053155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.048363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.050049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.041175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.033366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_idx      Pi_j\n",
       "0           1  0.042595\n",
       "1           2  0.051557\n",
       "2           3  0.050759\n",
       "3           4  0.052090\n",
       "4           5  0.051025\n",
       "5           6  0.052533\n",
       "6           7  0.051646\n",
       "7           8  0.052533\n",
       "8           9  0.052888\n",
       "9          10  0.052711\n",
       "10         11  0.053066\n",
       "11         12  0.052711\n",
       "12         13  0.052445\n",
       "13         14  0.052711\n",
       "14         15  0.052622\n",
       "15         16  0.053155\n",
       "16         17  0.048363\n",
       "17         18  0.050049\n",
       "18         19  0.041175\n",
       "19         20  0.033366"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_prob = Y.groupby(['label_idx']).agg({'doc_idx': 'count'})/len(Y)\n",
    "class_prob = class_prob.rename(columns = {'doc_idx': 'Pi_j'})\n",
    "class_prob = class_prob.reset_index()\n",
    "class_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P<sub>j</sub>\n",
    "### Find the probability distribution over V that models the documents for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000016915"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_jw = pd.merge(X,Y,how='inner',on='doc_idx')\n",
    "P_jw = P_jw.groupby(['word_idx', 'label_idx']).agg({'occurance_count':sum}).reset_index()\n",
    "\n",
    "P_jw = pd.merge(right=P_jw, left=s, how='outer', on=['word_idx','label_idx']).fillna(value=0)\n",
    "P_jw['x_smooth'] = P_jw['occurance_count']+1\n",
    "P_jw = P_jw.groupby(['label_idx', 'word_idx']).agg({'x_smooth':sum})\n",
    "P_jw = P_jw.groupby(level=0).transform(lambda x: x/x.sum())\n",
    "P_jw.columns = ['P_j']\n",
    "#P_jw['P_j'] = P_jw['x_smooth'] / sum(P_jw['x_smooth'] )\n",
    "P_jw = P_jw.reset_index()\n",
    "P_jw[P_jw['label_idx'] == 20].P_j.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying new documents\n",
    "This function takes a dataframe with doc_idx, word_idx, and count and classifies it to return a dataframe with the document_id and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_idx</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_idx  label_idx\n",
       "0        4         16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify(data):\n",
    "    a = pd.merge(data, P_jw, on='word_idx')\n",
    "    b = pd.merge(a, class_prob, on='label_idx' )\n",
    "    b['xlogp'] = b['occurance_count']*b['P_j'].apply(lambda x: log(x))\n",
    "    b = b.groupby(['doc_idx', 'label_idx', 'Pi_j']).agg({'xlogp':sum})\n",
    "    b = b.reset_index()\n",
    "    b['logPi_j'] = b['Pi_j'].apply(lambda x: log(x))\n",
    "    b['calc'] = b['logPi_j'] + b['xlogp']\n",
    "    b[['doc_idx','label_idx', 'calc']]\n",
    "    idx = b.groupby(['doc_idx'])['calc'].transform(max) == b['calc']\n",
    "    predict = b[idx][['doc_idx','label_idx']].reset_index()\n",
    "    return predict[['doc_idx', 'label_idx']]\n",
    "\n",
    "#this is to test the classifier\n",
    "test_classifier_data = X_test[X_test['doc_idx']==4]\n",
    "classify(test_classifier_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy\n",
    "This checks the accuracy of the model againsts all of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.76767676767676"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_accuracy(data, label):\n",
    "    predict = classify(data)\n",
    "    check = pd.merge(label, predict, on=['doc_idx'])\n",
    "    check['compare'] = check['label_idx_x'] - check['label_idx_y']\n",
    "    accuracy = len(check[check['compare'] == 0])*100/len(check)\n",
    "    return accuracy\n",
    "    \n",
    "#this is to test the classifier\n",
    "test_classifier_data = X_test[X_test['doc_idx']<100]\n",
    "test_classifier_label = Y_test[Y_test['doc_idx']<100]\n",
    "check_accuracy(test_classifier_data, test_classifier_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 78.107928048\n",
      "Error Rate:  21.892071952\n"
     ]
    }
   ],
   "source": [
    "c = check_accuracy(X_test, Y_test)\n",
    "print \"Precision:\", c\n",
    "#Error Rate:\n",
    "print \"Error Rate: \", 100-c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better-performing Model\n",
    "Get a better performing mode.  Currently, I'm at an accuracy of 78%.  If I want to get a better match..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the training model into a smaller training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 15.548455804046853],\n",
       " [5, 15.002219263204623],\n",
       " [6, 13.84451544195953],\n",
       " [7, 14.045991298943449],\n",
       " [8, 13.849431818181813],\n",
       " [9, 11.341853035143771],\n",
       " [10, 13.94316163410302],\n",
       " [11, 14.0625],\n",
       " [12, 12.034078807241741],\n",
       " [13, 14.31870669745959],\n",
       " [14, 13.805970149253724],\n",
       " [15, 13.98135818908122],\n",
       " [16, 14.630681818181813],\n",
       " [17, 13.74622356495469],\n",
       " [18, 11.821086261980824],\n",
       " [19, 13.827993254637434],\n",
       " [20, 12.433392539964473],\n",
       " [21, 14.179104477611943],\n",
       " [22, 13.671875],\n",
       " [23, 13.70143149284253],\n",
       " [24, 12.153518123667382]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the vocab\n",
    "def vocab(words,label_count,reduce_vocab=False):\n",
    "    ##tweek vocabulary here\n",
    "    if reduce_vocab == True:\n",
    "        words = words[:40000]\n",
    "\n",
    "    s = pd.Series([i+1 for i in range(label_count)], index=[i+1 for i in range(20)]).to_frame()\n",
    "    s['key'] = 1\n",
    "    s.columns = ['label_idx', 'key']\n",
    "    s = pd.merge(words, s, on='key')\n",
    "    return s\n",
    "\n",
    "#next get Pi_j\n",
    "def Pi_j(label):\n",
    "    class_prob = label.groupby(['label_idx']).agg({'doc_idx': 'count'})/len(Y)\n",
    "    class_prob = class_prob.rename(columns = {'doc_idx': 'Pi_j'})\n",
    "    class_prob = class_prob.reset_index()\n",
    "    return class_prob\n",
    "\n",
    "#now get P_jw\n",
    "def P_jw(data, label, vocab):\n",
    "    #use inputs here\n",
    "    P_jw = pd.merge(data,label,how='inner',on='doc_idx')\n",
    "    s = vocab\n",
    "    \n",
    "    #calcs here\n",
    "    P_jw = P_jw.groupby(['word_idx', 'label_idx']).agg({'occurance_count':sum}).reset_index()\n",
    "    P_jw = pd.merge(right=P_jw, left=s, how='outer', on=['word_idx','label_idx']).fillna(value=0)\n",
    "    P_jw['x_smooth'] = P_jw['occurance_count']+1\n",
    "    P_jw = P_jw.groupby(['label_idx', 'word_idx']).agg({'x_smooth':sum})\n",
    "    P_jw = P_jw.groupby(level=0).transform(lambda x: x/x.sum())\n",
    "    P_jw.columns = ['P_j']\n",
    "    P_jw = P_jw.reset_index()\n",
    "    \n",
    "    return P_jw\n",
    "\n",
    "def classify(data, P_jw, Pi_j):    \n",
    "    #use inputs here\n",
    "    a = pd.merge(data, P_jw, on='word_idx')\n",
    "    b = pd.merge(a, Pi_j, on='label_idx' )\n",
    "    \n",
    "    \n",
    "    b['xlogp'] = b['occurance_count']*b['P_j'].apply(lambda x: log(x))\n",
    "    b = b.groupby(['doc_idx', 'label_idx', 'Pi_j']).agg({'xlogp':sum})\n",
    "    b = b.reset_index()\n",
    "    b['logPi_j'] = b['Pi_j'].apply(lambda x: log(x))\n",
    "    b['calc'] = b['logPi_j'] + b['xlogp']\n",
    "    b[['doc_idx','label_idx', 'calc']]\n",
    "    idx = b.groupby(['doc_idx'])['calc'].transform(max) == b['calc']\n",
    "    predict = b[idx][['doc_idx','label_idx']].reset_index()\n",
    "    \n",
    "    return predict[['doc_idx', 'label_idx']]\n",
    "\n",
    "def check_accuracy(data, label, P_jw, Pi_j):\n",
    "    predict = classify(data, P_jw, Pi_j)\n",
    "    check = pd.merge(label, predict, on=['doc_idx'])\n",
    "    check['compare'] = check['label_idx_x'] - check['label_idx_y']\n",
    "    accuracy = len(check[check['compare'] == 0])*100/len(check)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#I'm going to split the data with a modulo of the doc_idx.\n",
    "# Modulo 4 gets every fourth doc_idx...which is roughly 25% of all documents\n",
    "# Modulo 5 gets every fifth doc_idx... which is roughly 20% of all documents\n",
    "# Modulo 6 gets every sixth doc_idx.. and so on\n",
    "results = []\n",
    "validation = []\n",
    "for i in range(4,25):\n",
    "    X_validate = X[X['doc_idx']%i == 0]\n",
    "    X_split = X[X['doc_idx']%i != 0]\n",
    "\n",
    "    Y_validate = Y[Y['doc_idx']%i == 0]\n",
    "    Y_split = Y[Y['doc_idx']%i != 0]\n",
    "\n",
    "    df_Pi_j = Pi_j(Y_split)\n",
    "    df_P_jw = P_jw(X_split, Y_split, vocab(V,20))\n",
    "    #classify(X_validate, df_P_jw, df_Pi_j)\n",
    "\n",
    "    validation.append([i, 100-check_accuracy(X_validate, Y_validate, df_P_jw, df_Pi_j)]) \n",
    "    #results.append([i, check_accuracy(X, Y, df_P_jw, df_Pi_j)])\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results\n",
    "#after running this, it seems that modulo 9 gets the highest accuracy for the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[4, 84.45154419595315],\n",
    " [5, 84.99778073679538],\n",
    " [6, 86.15548455804047],\n",
    " [7, 85.95400870105655],\n",
    " [8, 86.15056818181819],\n",
    " [9, 88.65814696485623],\n",
    " [10, 86.05683836589698],\n",
    " [11, 85.9375],\n",
    " [12, 87.96592119275826],\n",
    " [13, 85.68129330254041],\n",
    " [14, 86.19402985074628],\n",
    " [15, 86.01864181091878],\n",
    " [16, 85.36931818181819],\n",
    " [17, 86.25377643504531],\n",
    " [18, 88.17891373801918],\n",
    " [19, 86.17200674536257],\n",
    " [20, 87.56660746003553],\n",
    " [21, 85.82089552238806],\n",
    " [22, 86.328125],\n",
    " [23, 86.29856850715747],\n",
    " [24, 87.84648187633262]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's tweek by eliminating the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#define the vocab\n",
    "def vocab(words,label_count,reduce_vocab=False):\n",
    "    ##tweek vocabulary here\n",
    "    if reduce_vocab == True:\n",
    "        words = [(word_idx,word, key) for (a, word,word_idx,key) in words.itertuples() if word not in stop_words]\n",
    "        words = pd.DataFrame(data=words, columns=['word_idx', 'word','key'])\n",
    "\n",
    "    s = pd.Series([i+1 for i in range(label_count)], index=[i+1 for i in range(20)]).to_frame()\n",
    "    s['key'] = 1\n",
    "    s.columns = ['label_idx', 'key']\n",
    "    s = pd.merge(words, s, on='key')\n",
    "    return s\n",
    "\n",
    "len(vocab(V,20,reduce_vocab=True)), len(vocab(V,20,reduce_vocab=False))\n",
    "\n",
    "validation = []\n",
    "for i in range(5,20):\n",
    "    X_validate = X[X['doc_idx']%i == 0]\n",
    "    X_split = X[X['doc_idx']%i != 0]\n",
    "\n",
    "    Y_validate = Y[Y['doc_idx']%i == 0]\n",
    "    Y_split = Y[Y['doc_idx']%i != 0]\n",
    "\n",
    "    df_Pi_j = Pi_j(Y_split)\n",
    "    df_P_jw = P_jw(X_split, Y_split, vocab(V,20,True))\n",
    "    validation.append([i, check_accuracy(X_validate, Y_validate, df_P_jw, df_Pi_j), True]) \n",
    "    \n",
    "    df_P_jw = P_jw(X_split, Y_split, vocab(V,20,False))\n",
    "    validation.append([i, 100-check_accuracy(X_validate, Y_validate, df_P_jw, df_Pi_j), False]) \n",
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try replacing the frequency (f) of a word by log(1+f)\n",
    "We will not use the modified Vocabulary (without stop_words), because it didn't really improve the overall precision of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def P_jw(data, label, vocab):\n",
    "    #use inputs here\n",
    "    P_jw = pd.merge(data,label,how='inner',on='doc_idx')\n",
    "    s = vocab\n",
    "    \n",
    "    #calcs here\n",
    "    P_jw = P_jw.groupby(['word_idx', 'label_idx']).agg({'occurance_count':sum}).reset_index()\n",
    "    P_jw = pd.merge(right=P_jw, left=s, how='outer', on=['word_idx','label_idx']).fillna(value=0)\n",
    "    \n",
    "    #this is where we replace the frequency of a word by log(1+f)\n",
    "    P_jw['x_smooth'] = P_jw['occurance_count'].apply(lambda x: log(x+2))\n",
    "    P_jw = P_jw.groupby(['label_idx', 'word_idx']).agg({'x_smooth':sum})\n",
    "    P_jw = P_jw.groupby(level=0).transform(lambda x: x/x.sum())\n",
    "    P_jw.columns = ['P_j']\n",
    "    P_jw = P_jw.reset_index()\n",
    "    \n",
    "    return P_jw\n",
    "\n",
    "results = []\n",
    "for i in range(9,10):\n",
    "    X_validate = X[X['doc_idx']%i == 0]\n",
    "    X_split = X[X['doc_idx']%i != 0]\n",
    "\n",
    "    Y_validate = Y[Y['doc_idx']%i == 0]\n",
    "    Y_split = Y[Y['doc_idx']%i != 0]\n",
    "\n",
    "    df_P_jw = P_jw(X_split, Y_split, vocab(V,20))\n",
    "    results.append([i, 100-check_accuracy(X_validate, Y_validate, df_P_jw, df_Pi_j), False])\n",
    "results\n",
    "#The results are not as good..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy out of the options I've tried comes from splitting the training data by modulo 9...and it doesn't matter whether we pull our the stop_words from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def P_jw(data, label, vocab):\n",
    "    #use inputs here\n",
    "    P_jw = pd.merge(data,label,how='inner',on='doc_idx')\n",
    "    s = vocab\n",
    "    \n",
    "    #calcs here\n",
    "    P_jw = P_jw.groupby(['word_idx', 'label_idx']).agg({'occurance_count':sum}).reset_index()\n",
    "    P_jw = pd.merge(right=P_jw, left=s, how='outer', on=['word_idx','label_idx']).fillna(value=0)\n",
    "    P_jw['x_smooth'] = P_jw['occurance_count']+1\n",
    "    P_jw = P_jw.groupby(['label_idx', 'word_idx']).agg({'x_smooth':sum})\n",
    "    P_jw = P_jw.groupby(level=0).transform(lambda x: x/x.sum())\n",
    "    P_jw.columns = ['P_j']\n",
    "    P_jw = P_jw.reset_index()\n",
    "    \n",
    "    return P_jw\n",
    "\n",
    "results = []\n",
    "i = 9\n",
    "\n",
    "X_validate = X[X['doc_idx']%i == 0]\n",
    "X_split = X[X['doc_idx']%i != 0]\n",
    "\n",
    "Y_validate = Y[Y['doc_idx']%i == 0]\n",
    "Y_split = Y[Y['doc_idx']%i != 0]\n",
    "\n",
    "df_P_jw = P_jw(X_split, Y_split, vocab(V,20))\n",
    "results.append([i, 100-check_accuracy(X, Y, df_P_jw, df_Pi_j), False])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
